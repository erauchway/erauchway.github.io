---
title: "AI and teaching history today"
date: "2026-01-21"
categories: 
    - Methods
    - Madness
draft: TRUE
---

This post documents my current thoughts on [AI,](#nomenclature) which I want to set down more or less to get them out of my head and also to have something to look back on as and when my thinking changes, as I know it already has [in the last couple years.](https://www.the-tls.com/science-technology/technology/the-handover-david-runciman-technofeudalism-yanis-varoufakis-book-review-eric-rauchway) Uncharacteristically for a historian, I am not going to talk about how we got here and specifically I am not going to talk about the ethics of taking people's work without permission or compensation (yes, [it happened to me too](https://secure.anthropiccopyrightsettlement.com/lookup/results)) or [environmental degradation.](https://www.unep.org/news-and-stories/story/ai-has-environmental-problem-heres-what-world-can-do-about) Those issues are real and vital, but I want here to think through what people like me, who have to go into university classrooms at the start of an academic term two or three times a year, to talk to undergraduate and graduate students about AI, need to think about in advance of those occasions, given that our institutions have already put these tools in our students' hands without much, if any, preparation. (There is [a UC primer](https://rise.articulate.com/share/B8DxWcOO3ALcVHlgqyQosNxIABqI7Pn4#/) that I do not want to discuss right now.)

## AI and students here (and possibly where you are)
UC Davis provides affiliates with 
- [Google workspace accounts,](https://servicehub.ucdavis.edu/servicehub?id=ucd_kb_article&sys_id=a706700d6f9ce100bc4f8a20af3ee455&spa=1) which means students have free access to Gemini 
- [A Microsoft Office site license](https://servicehub.ucdavis.edu/servicehub?id=ucd_kb_article&sys_id=6a661eae6f5b65002f5fe811af3ee4b4&spa=1) which means students have free access to Copilot 
- Access [to ChatGPT](https://iet.ucdavis.edu/aggie-ai/chatgpt-edu/get-started) 
- An OpenAI-powered local LLM ([sorry](#nomenclature)) called [Rocky.](https://iet.ucdavis.edu/aggie-ai/ai-tools/rocky)
- Zoom with built-in [AI features](https://iet.ucdavis.edu/aggie-ai/ai-tools/zoom-ai-companion)

To the best of my knowledge we do not have Claude Code freely available on campus, which is odd because it is the AI application IT people are most likely to tell you does, genuinely, work as advertised.

In addition to the above, many of our students have Apple products with Apple Intelligence. When they use the library website to access monographs, they are offered AI summaries by the database provider. And of course they can go further afield and get [other AI tools](https://chat.deepseek.com/) on their own.

As you can see, our students move through an environment in which they can scarcely escape some kind of AI. 

## AI for reading and writing
AI has no place in student reading or writing. Explaining this conviction to students, I say two things:
1. It doesn't do what you want it to do. 
    Its [summaries are inaccurate.](https://royalsocietypublishing.org/rsos/article/12/4/241776/235656/Generalization-bias-in-large-language-model) It produces fake citations and [no amount of improving may eliminate that.](https://www.nature.com/articles/d41586-025-02853-8)

    As for its writing, it is, at best, bad. It sounds like [bullshit---which is of course what it is;](https://www2.csudh.edu/ccauthen/576f12/frankfurt__harry_-_on_bullshit.pdf) language without meaning. And honestly that means it presents me with no real difficulty: I've been giving low marks to bullshit essays for longer than most of today's students have been alive; back in the day I did it to artisanally hand-crafted bullshit and now I do it to machine-produced bullshit. Nobody wants you to hand in a bullshit essay and if you do, your grade will reflect it.

    (I will sometimes go into greater detail on what I mean here, but I think most of us know what a bullshit essay sounds like. Its chief features are excessive prefatory matter and padding throughout, and mealy-mouthed theses and topic sentences.)
    
2. Even if it did what you wanted it to do, that would be bad for your education. 
    We don't assign you reading because we want certain essential information to travel from the books into your brain. We assign you reading because we want your brain to work through the argument in the book. We don't assign you writing because we want to have an essay from you. We assign you writing because we want your brain to work through the process of turning your thoughts into sentences and paragraphs. 

    Using an AI to read or write is [like taking a forklift to the gym.](https://www.alfiekohn.org/article/ai/) I'm sure the analogy is clear but just in case let me spell it out: the point of going to the gym is not for the weights to go up and down, it's for your body to have the experience of moving the weights up and down.

    Just as going to the gym conditions your body, doing classwork conditions your mind. Which is why we are here in the classroom.

And the same applies to scholarly reading or writing. The bedrock notion of scholarly integrity is that you should do your own work and should not claim the work of another as your own.

## But what about. . . .
There are tasks historians undertake that are not reading or writing. What about them?

Many historians code and as noted above, Claude Code is the application on whose utility computer-literate people are most likely to agree. 

<a id="nomenclature"></a>
## What we call it
"AI" is a misnomer and/or sales tactic; we should be talking about "large language models" or LLMs. But I feel like fighting the terminology battle is a losing proposition so I'm going to say "AI."